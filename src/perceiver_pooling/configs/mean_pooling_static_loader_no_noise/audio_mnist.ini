[MODEL_PARAMETERS]
NUM_LATENTS = 32
LATENT_DIM = 64
INPUT_CHANNELS = 64
INPUT_AXIS = 1
SELF_PER_CROSS_ATTENTION = 3
CROSS_HEADS = 4
CROSS_DIM_HEAD = 96
CROSS_ATTENTION_DROPOUT = 0.1
LATENT_HEADS = 2
LATENT_DIM_HEAD = 96
LATENT_ATTENTION_DROPOUT = 0.1
TIE_WEIGHT_POS_CROSS_ATTENTION = 2
TIE_WEIGHT_POS_LATENT_ATTENTION = 2
ITERATIVE_COUNT = 3
FOURIER_ENCODE_DATA = YES
NUM_FREQ_BANDS = 16
MAX_FREQ = 10
CROSS_ATTENTION_FEED_FORWARD_DROPOUT = 0.1
LATENT_ATTENTION_FEED_FORWARD_DROPOUT = 0.1
USE_HOPFIELD_POOLING = no
HOPFIELD_DIM_HEAD = 16
HOPFIELD_HEADS = 2
HOPFIELD_LATENT_ATTENTION_POS = 3
HOPFIELD_MAX_UPDATE_STEPS = 2
HOPFIELD_SCALING = 0.1
HOPFIELD_DROPOUT = 0.2


[DATA]
TRAIN_DATA_PATH = ./datasets/audio_mnist/train_annotations.json
VAL_DATA_PATH = ./datasets/audio_mnist/val_annotations.json
__TEST_DATA_PATH__ = ./datasets/audio_mnist/test/annotations.json
# make it possible to map paths and readers (parse_config.py)
# make sure that the name of the following methods is mapped in parse_config -> map_data_function
TRAIN_LOAD_DATA_METHOD = mnist_audio
VAL_LOAD_DATA_METHOD = mnist_audio
__TEST_LOAD_DATA_METHOD__ = mnist_audio
